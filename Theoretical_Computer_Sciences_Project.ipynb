{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical Computer Sciences Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sergio Peignier and Théotime Grohens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Libraries to install before starting** :\n",
    "\n",
    "> pip install pqdict\n",
    "\n",
    "> pip install community\n",
    "\n",
    "> pip install python-louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pqdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import community as community_louvain\n",
    "import math "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Graph Therory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will apply graph algorithms to study the gene regulatory network (GRN)\n",
    "of *Saccharomyces cerevisiae*. This species of yeast, it is a small single-cell eukaryote, with a short generation time, and two possible forms: an haploid one and a diploid one. Moreover, this organism can be easily cultured, and it has an important economic impact since it is extensively used for instance,\n",
    "in winemaking, baking, and brewing. Due to these characteristics, Saccharomyces cerevisiae\n",
    "is studied as an important model organism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this work we will study the **gene regulatory network** of *Saccharomyces cerevisiae*, using graph theory algorithms. The files that are provided for this project have been used in [MCK+12] , as gold-standards to assess gene regulatory network inference algorithms, and they are the result of biological experiments based on ChIP binding data [MWG + 06], and systematic transcription factor deletions [HKI07]. Hereafter we describe each dataset in details:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GRN_edges_S_cerevisiae.txt : contains the edges of the *S. cervisiae* regulatory network (from transcription factors to target genes). The intended meaning is that if there is an edge between transcription factor X and the target gene A, then X regulates the transcription of A ;\n",
    "\n",
    "- net4_transcription_factors.tsv : Is a file containing in a single column the identifiers of the transcription factors of *S. cervisiae* that were studied ;\n",
    "\n",
    "- net4_gene_ids.tsv : The two previous files, use specific identifiers to denote genes, and this file contains the gene name associated to each gene identifier ;\n",
    "\n",
    "- go_slim_mapping.tab.txt : Only columns 0 and 5 will be used in this work. Column 0 contains the gene name, and column 5 contains its Gene Ontology (GO) annotation (http://www.geneontology.org/). Notice that two different rows may give for the same gene different Gene Ontology annotations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Exploration and characterization of the gene regulatory network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 - Load the dataset and create a NetworkX graph instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On importe les datasets avec pandas : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X : transcription factors\n",
    "# A : genes\n",
    "GRN_edges_SC = pd.read_csv(\"./datas/GRN_edges_S_cerevisiae.txt\", sep = ',',  header=0) # edges X -> A\n",
    "net4_transcription_factors = pd.read_csv(\"./datas/net4_transcription_factors.tsv\", sep = '\\n',  header=0) # X ID\n",
    "net4_gene_ids = pd.read_csv(\"./datas/net4_gene_ids.tsv\", sep = '\\t', header=0) # A ID -> Name\n",
    "go_slim_mappingtab = pd.read_csv(\"./datas/go_slim_mapping.tab.txt\", sep = '\\t', header=None) # A [0]Name -> [5]GO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRN_edges_SC = GRN_edges_SC.iloc[:,1:] # the first column isn't relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vérifie que tout a bien été importé "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on peut transformer le df en array (au cas où si besoin)\n",
    "GRN_edges_SC_np = GRN_edges_SC.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net4_gene_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net4_transcription_factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_slim_mappingtab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRN_edges_SC.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le dataset a bien été importé, on créé donc un graphe $G = <V,E>$ dont l'ensemble des noeuds noté $V$ contient les facteurs de transcription et les gènes cibles et l'ensemble des arettes noté $E$ représente les régulations des gènes par les facteurs de transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(GRN_edges_SC, \"transcription_factor\", \"target_gene\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 - Plot the gene regulatory network,  the plot should be readable,  understandable,  andinformative.  Which information did you decide to convey in your plot?  Why?\n",
    "\n",
    "On représente le graphe G tel quel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Premiere impression pour le graphe \n",
    "plt.figure(figsize=(15,8))\n",
    "nx.draw(G, node_size = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ensemble $V$ peut être séparé en deux sous-ensembles :\n",
    "\n",
    "- $X$ : ensemble des facteurs de transcription ;\n",
    "- $A$ : ensemble des gènes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gn_nodes = [a for a in GRN_edges_SC[\"target_gene\"]]\n",
    "tf_nodes = [x for x in GRN_edges_SC[\"transcription_factor\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.kamada_kawai_layout(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On rend le graphe plus lisible \n",
    "plt.figure(figsize=(18,10))\n",
    "#pos = nx.spring_layout(G, k = 0.6,) #return the relative positions of the nodes,k = optimal distance between nodes\n",
    "\n",
    "# nodes\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=gn_nodes, node_color=\"r\", node_size= 18, label = \"gene's nodes\")\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=tf_nodes, node_color=\"b\", node_size= 18, label = \"TGF's nodes\")\n",
    "\n",
    "# edges\n",
    "nx.draw_networkx_edges(G, node_size = 18, pos = pos, width = 0.4, edge_color = 'DarkSlateGray')\n",
    "\n",
    "plt.legend()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If it's a Bipartite Graph :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import bipartite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BG =  nx.Graph()\n",
    "BG.add_nodes_from(GRN_edges_SC['transcription_factor'], bipartite = 'transcription_factor')\n",
    "BG.add_nodes_from(GRN_edges_SC['target_gene'], bipartite = 'target_gene')\n",
    "BG.add_edges_from(zip(GRN_edges_SC['transcription_factor'], GRN_edges_SC['target_gene']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf = transcription_factor\n",
    "tf_nodes = [ n for n in BG.nodes() if BG.nodes[n]\n",
    "            ['bipartite'] == 'transcription_factor']\n",
    "\n",
    "# gn = gene = target_gene\n",
    "gn_nodes = [ n for n in BG.nodes() if BG.nodes[n]\n",
    "           ['bipartite'] == 'target_gene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posBG = nx.bipartite_layout(BG, tf_nodes, scale = 1)\n",
    "plt.figure(figsize=(30,20))\n",
    "nx.draw(BG, pos = posBG, node_size = 14,\n",
    "       node_color = 'forestgreen',\n",
    "       edge_color = 'darkblue',\n",
    "       width = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 - Describe the network by computing pertinent local and global metrics,  explain your choices, represent the results graphically if necessary, and interpret the results.\n",
    "##### 1.1.3.1 - Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_degree = {x : len(G[x]) for x in tf_nodes} \n",
    "gn_degree = {a : len(G[a]) for a in gn_nodes}\n",
    "degree = [[xd for xd in tf_degree.values()], [ad for ad in gn_degree.values()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.xticks(np.arange(0, 300, step=10), fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Degree\",fontsize=20)\n",
    "plt.ylabel(\"Nodes (%)\",fontsize=20)\n",
    "plt.title(\"Histogram of degrees\", fontsize=20)\n",
    "\n",
    "deg_tf = degree[0]\n",
    "deg_gn = degree[1]\n",
    "plt.hist([deg_tf, deg_gn], color = ['mediumorchid', 'coral'], \n",
    "         edgecolor = 'black', label = [\"TF's nodes\", \"gene's nodes\"], density = True, bins = 50)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genes have a lower degree ($\\lt 15$) than transcription factors which can have a very high degree. This seems logical as the transcription factors can regulate several genes and can be regulated by other TF but genes that doesn't code for a TF are at the end of this regultation chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.3.2 - Clusturing coefficient\n",
    "\n",
    "$C(v_i) = \\frac{|neighbors\\_of\\_v_i\\_connected|}{|pair\\_of\\_distinct\\_neighbors\\_of\\_v_i|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(G, V = G.nodes()) :\n",
    "    # Computes the clusturing coefficient of the nodes in V\n",
    "    # G : networkx graph\n",
    "    # v : list of nodes of G\n",
    "    # returned value : dict {node : int}, the int beeing the clusturing coefficiten of the node\n",
    "    \n",
    "    clust = {v : 0 for v in V} # returned value : clusturing coefficiten of each node\n",
    "    \n",
    "    for v in V : \n",
    "        e_neigh = 0 # number of edges between the neighbors of v\n",
    "        deg = len(G[v]) # degree of v\n",
    "        if deg > 1 :\n",
    "            for neigh1 in G[v] :\n",
    "                for neigh2 in G[neigh1] :\n",
    "                    if neigh2 in G[v] :\n",
    "                        e_neigh += 1\n",
    "        \n",
    "            clust[v] = e_neigh/(deg*(deg-1))\n",
    "        \n",
    "    return clust    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time complexity of each loop, n beeing the number of nodes in V :\n",
    "\n",
    "- `for v in V :` $n$\n",
    "    - `for neigh1 in G[v] :` $n-1$\n",
    "        - `for neigh2 in G[neigh1] :` $n-1$\n",
    "    \n",
    "So the time complexity of `clustering` is $O(n^3)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_clust = clustering(G, tf_nodes)\n",
    "gn_clust = clustering(G, gn_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_mean_clust = np.mean([x for x in tf_clust.values()])\n",
    "gn_mean_clust = np.mean([x for x in gn_clust.values()])\n",
    "tf_sd_clust = np.std([x for x in tf_clust.values()])\n",
    "gn_sd_clust = np.std([x for x in gn_clust.values()])\n",
    "\n",
    "\n",
    "print(\"Mean clustering coefficient TF :\", tf_mean_clust, \"sd :\", tf_sd_clust)\n",
    "print(\"Mean clustering coefficient genes :\", gn_mean_clust, \"sd :\", gn_sd_clust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clustering coefficient of the nodes in the gene regulatory network is very low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap (G):\n",
    "    out = []\n",
    "    for couple in nx.utils.pairwise(G.nodes()):\n",
    "        n = 0\n",
    "        for nei in G[couple[0]]:\n",
    "            if nei in G[couple[1]]:\n",
    "                n+=1\n",
    "        if n == 0:\n",
    "            O = 0\n",
    "        elif  G.degree(couple[0]) <= 1 or G.degree(couple[1]) <= 1:\n",
    "            O = 0\n",
    "        elif (G.degree(couple[0])-1+G.degree(couple[1])-1-n) == 0:\n",
    "            print(G.degree(couple[0]),G.degree(couple[1]),n)\n",
    "            O=100\n",
    "        else :\n",
    "            O =  n/(G.degree(couple[0])-1+G.degree(couple[1])-1-n)\n",
    "        out.append((couple, O))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.closeness_centrality(G) # inverse de la dist moyenne entre n et les autre noeuds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.betweenness_centrality(G) # fraction of shortest paths that passes through n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.density(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RC = nx.rich_club_coefficient(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = sorted(RC.items()) # sorted by key, return a list of tuples\n",
    "\n",
    "x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"Degree k\",fontsize=10)\n",
    "plt.ylabel(\"Rich Club Coefficient\",fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_degree_dist(G):\n",
    "    degrees = [G.degree(n) for n in G.nodes()]\n",
    "    plt.hist(degrees)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_freq = nx.degree_histogram(G)\n",
    "degrees = range(len(degree_freq))\n",
    "plt.figure(figsize=(12, 8)) \n",
    "plt.loglog(degrees, degree_freq) \n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Implement and apply the k-shell decomposition algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first try to make a k-shell with a function `k_shell` directly implemented in the `networkx.algorithms.core` library, for different $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.core import k_shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(nx.k_shell(G, k=2), node_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(k_shell(G, k=4), node_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(k_shell(G, k=6), node_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(k_shell(G, k=7), node_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $k > 7$ there is no more node left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet we try to implement ourself the `k_shell` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_kshell (G, k) :\n",
    "    degrees = []\n",
    "    GG = nx.Graph()\n",
    "    GG.add_nodes_from(G)\n",
    "    GG.add_edges_from(G.edges)\n",
    "    \n",
    "    ik = 1\n",
    "    for ik in range(k):\n",
    "        done = False\n",
    "        while not done :\n",
    "            rm = []\n",
    "            for n in GG.nodes():\n",
    "                if GG.degree(n)<=ik:\n",
    "                    rm.append(n)\n",
    "            for m in rm:\n",
    "                GG.remove_node(m)\n",
    "            done = True\n",
    "            for n in GG.nodes():\n",
    "                if GG.degree(n)<=ik:\n",
    "                    done = False\n",
    "                    break\n",
    "            \n",
    "    return GG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_G = my_kshell(G, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(new_G, node_size = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) For at least 4 of the metrics that you have used:  what is the time complexity of the algorithm that calculates it (explain)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 : Community detection\n",
    "\n",
    "#### 1) You can choose between the Girvan Newman method and the Louvain algorithm tofind communities in the graph. Describe both algorithms, and their time complexities (explain)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Girvan Newman method :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can express Girvan-Newman algorithm in the following procedure:\n",
    "- Calculate edge betweenness for every edge in the graph ;\n",
    "- Remove the edge with highest edge betweenness ;\n",
    "- Calculate edge betweenness for remaining edges ;\n",
    "- Repeat steps 2–4 until all edges are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In its simplest and fastest form - worst-case time $O(E^{2}V$) on a network with $E$ edges and $V$ vertices, or $O(E^{3})$ on a sparse graph (where $V = E$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Louvain algorithm :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method consists of two phases :\n",
    "- The first step is to look for \"small\" communities by optimizing modularity in a local way, where the modularity quantifies the quality of an assignment of nodes to communities. \n",
    "- The second step consist of an aggregation of nodes from the same community and to build a new network whose nodes are the communities. \n",
    "\n",
    "These steps are repeated iteratively until a maximum of modularity is attained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The algorithm is:\n",
    "\n",
    "- Start with each node being a singleton cluster: \n",
    "- Consider nodes in random order.\n",
    "- Iterate as long as cluster membership changes \n",
    "     - for each node : remove it from its current cluster and add it to the cluster with the highest modularity gain \n",
    "- aggregate the resulting clustering to a new graph and continue on next level (step 1), as long as modularity improves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time complexity of the Louvain algorithm is $O(V \\log(V))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the module *community* implements a community detection unsing the Louvain method because this method has the best time complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_partition = community_louvain.best_partition(G, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modularity = community_louvain.modularity(louvain_partition, G, weight='weight')\n",
    "print(\"The modularity Q of G is {}\".format(modularity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "\n",
    "size = float(len(set(louvain_partition.values())))\n",
    "pos = nx.spring_layout(G)\n",
    "count = 0\n",
    "cmap = cm.get_cmap('viridis', max(louvain_partition.values()) + 1)\n",
    "nx.draw_networkx_nodes(G, pos, louvain_partition.keys(), node_size=18, cmap=cmap, node_color=list(louvain_partition.values()))\n",
    "nx.draw_networkx_edges(G, node_size = 18, pos = pos, width = 0.5, edge_color = 'DarkSlateGray', alpha= 0.6)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dendrogram is a tree and each level is a partition of the graph nodes.  Level 0 is the first partition, whichcontains the smallest communities, and the best is len(dendrogram) - 1.  The higher the level is, the bigger arethe communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dendrogram = community_louvain.generate_dendrogram(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dendrogram[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Which algorithm did you choose, why ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) For the the Girvan Newman method, the user should select one of the output partitions, explain the criterion that could be used to make this choice, and its complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Study the GO composition of each community.  To do this you can produce a countingmatrix $M$,  such  that $M_{i,j}$ is  the  number  of  genes  from  community $j$ that  have  GO annotation $i^1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Is there a relationship between graph communities and particular cell functions ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Around the Traveling Salesman Problem\n",
    "### 2.1 - Exact solution\n",
    "#### 2.1.1 - Number of Hamiltonian paths in a complete graph\n",
    "\n",
    "In a complete graph, every node is adjacent to every other node. Let $G = (V, E)$ a complete graph with $|V| = n$. Let's define an Hamiltonian path $(x_0, x_1, x_2,...,x_n)$ in $G$. There are $n$ possible starting nodes $x_0$. Then, as one of the $n$ nodes has already been visited, only $n-1$ options are left for $x_1$, $n-2$ for $x_2$ and so on until there is only one node left unvisited : $x_n$. Thus, there are $n\\times n-1 \\times n-2 \\times ... \\times 1 = n!$ distinct Hamiltonian paths in a complete graph of size $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 - Test graphs creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a complete graph to test our functions\n",
    "Gc = nx.Graph()\n",
    "Gc = nx.complete_graph(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
    "list(Gc.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weight(G) : \n",
    "    # Modifies G to add a random int weight in ]0,10]\n",
    "    # G : networkX graph\n",
    "    for e in G.edges():\n",
    "        G[e[0]][e[1]]['weight'] = random.randrange(0,10)+1\n",
    "        #print(e, Gc[e[0]][e[1]]['weight']) \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def draw_weight(G):\n",
    "    # Draws the graph G where each edge's width is proportional to its weight\n",
    "    # G : weighted networkX graph\n",
    "    \n",
    "    edge_width = [d['weight'] for (u, v, d) in G.edges(data=True)] # weight of the edges of G\n",
    "\n",
    "    pos = nx.spring_layout(G)  # positions for all nodes\n",
    "\n",
    "    # nodes\n",
    "    nx.draw_networkx_nodes(G, pos)\n",
    "\n",
    "    # edges\n",
    "    nx.draw_networkx_edges(G, pos, width=edge_width)\n",
    "\n",
    "    # labels\n",
    "    nx.draw_networkx_labels(G, pos, font_size=20, font_family=\"sans-serif\")\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_weight(Gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_weight(Gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a different graph to test our functions\n",
    "Gtest = nx.petersen_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_weight(Gtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_weight(Gtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 - Enumeration of Hamiltonian paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_step(G, si, path, weight, path_weight) :\n",
    "    # Step to compute all possible paths that go as deep as possible from si without any nodes already in path,\n",
    "    # also computes corresponding weight of these paths\n",
    "    # G : weighted networkX graph\n",
    "    # si : node of G, active node\n",
    "    # path : list of nodes of G, active path\n",
    "    # weight : int, weight of the active path\n",
    "    # path_weight : list of tuples (path, weight), \n",
    "    # each path is represented as a list of nodes, its total weight as an int\n",
    "    \n",
    "    if len(path)>0 : # if si is not the fist node of the path\n",
    "        sp = path[len(path)-1] # last node in path\n",
    "        si_w = G[sp][si]['weight'] # weight of the edge between sp and si\n",
    "        weight = weight + si_w # weight update\n",
    "        \n",
    "    path = path + [si] # si is added to the path\n",
    "    \n",
    "    # si_succ is filled with the successors of si that are not already in path\n",
    "    si_succ = [] \n",
    "    for sj in G[si] :\n",
    "        if sj not in path :\n",
    "            si_succ.append(sj)\n",
    "    \n",
    "    # next_step is called for each succesor sj\n",
    "    for sj in si_succ :\n",
    "        next_step(G, sj, path, weight, path_weight)\n",
    "    \n",
    "    # when each branch has been visited as deep as possible, the list of pathecessor is added to path\n",
    "    if len(si_succ) == 0 :\n",
    "        path_weight.append((path, weight))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hamiltonian_path(G, s0) :\n",
    "    # Computes the the possible Hamiltonian paths in G starting at node s0\n",
    "    # G : weighted networkX graph\n",
    "    # s0 : node in G\n",
    "    # returned value : list of tuples (path, weight)\n",
    "    # each path is represented as a list of nodes, its total weight as an int\n",
    "    \n",
    "    # computing all possible paths that go as deep as possible and start at s0 and their corresponding weight\n",
    "    \n",
    "    path = [] # active path\n",
    "    path_weight = [] # list of tuples (path, weight) to contain the paths and their weight\n",
    "    weight = 0 # weight of the active path\n",
    "    \n",
    "    # first step\n",
    "    # active node : s0\n",
    "    next_step(G, s0, path, weight, path_weight) \n",
    "    \n",
    "    \n",
    "    # Filtering path_w to keep only the Hamiltonian paths \n",
    "    \n",
    "    n = len(G.nodes()) # size of G\n",
    "    ham_path = [] \n",
    "    for tup in path_weight :\n",
    "        if len(tup[0]) >= n :\n",
    "            ham_path.append(tup)\n",
    "          \n",
    "    return ham_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Hamiltonian_path(Gtest, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gc_path = Hamiltonian_path(Gc, 'a')\n",
    "Gc_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_Gc_path = len(Gc_path) # number of Hamiltonian paths found starting at node 'a' in Gc\n",
    "n = len(Gc.nodes()) # size of Gc\n",
    "print(N_Gc_path == math.factorial(n-1)) # test N_Gc_path == (n-1)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we showed before, we can find $n!$ Hamiltonian paths in a complete graph of size $n$. Here we know the starting node $n_1$ so we don't have the $n$ options for $n_1$ but only one, so we end up with $\\frac{n!}{n} = (n-1)!$ Hamiltonian paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 - Shortest Hamiltonian path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path(path_w) :\n",
    "    # returns the shortest(s) path(s) of path_w\n",
    "    # if there are several paths of the same minimal weight they will be all returned\n",
    "    # path_w : list of tuples (path, weight)\n",
    "    # each path is represented as a list of nodes, its total weight as an int\n",
    "    # returned value : tuples (path, weight) \n",
    "    \n",
    "    w_min = path_w[0][1] # minimal weight initialisation\n",
    "    path_min = [] # shortest path initialisation\n",
    "    \n",
    "    # searching for the lowest weight\n",
    "    for tup in path_w :\n",
    "        if tup[1] < w_min : # if a lower weight is found\n",
    "            w_min = tup[1] # minimal weight actualisation\n",
    "            path_min = [tup] # shortest path actualisation\n",
    "        elif tup[1] == w_min : # if there is a path of the same weight as path_min\n",
    "            path_min.append(tup) # this path is added to the list of shortest paths\n",
    "            \n",
    "    return path_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_ham_path(G, s0) :\n",
    "    # returns the shortest(s) Hamiltonian path(s) in G starting at node s0\n",
    "    # if there are several paths of the same minimal weight they will be all returned\n",
    "    # G : weighted networkX graph\n",
    "    # s0 : node in G\n",
    "    # returned value : list of tuples (path, weight)\n",
    "    # each path is represented as a list of nodes, its total weight as an int\n",
    "    \n",
    "    path_w = Hamiltonian_path(G, s0)\n",
    "    path_min = shortest_path(path_w)\n",
    "            \n",
    "    return path_min\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gc_min_path = shortest_ham_path(Gc, 'a')\n",
    "Gtest_min_path = shortest_ham_path(Gtest, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gc_min_path', Gc_min_path)\n",
    "print('Gtest_min_path', Gtest_min_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the research of all Hamiltonian paths, `si_succ`, on which we loop, gets smaller as we go deeper. For `si = s0`, the maximum size of `si_succ` is $n$ (if we can have an edge that liks `si` to itself), then as we go a step deeper, the maximum size of `si_succ` is $n-1$, then $n-2$, and so on. The time complexity of the method `Hamiltonian_path` is $O(n!)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5 - Traveling Salesman exact solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Traveling_Salesman(G) :\n",
    "    # Returns all possible solutions to the traveling salesman problem for the graph G\n",
    "    # G : weighted networkX graph\n",
    "    # returned value : list of tuples (path, weight)\n",
    "    # each path is represented as a list of nodes, its total weight as an int\n",
    "    \n",
    "    # searching shortests Hamiltonian paths in G for each of its nodes as starting node\n",
    "    path_w = []\n",
    "    for s in G.nodes() :\n",
    "        path_w = path_w + Hamiltonian_path(G, s)\n",
    "    \n",
    "    # finding the shortest(s) path(s) in the Hamilton paths found\n",
    "    path_min = shortest_path(path_w)\n",
    "    \n",
    "    return path_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Traveling_Salesman(Gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Traveling_Salesman(Gtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - The Nearest Neighbor heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbour(G, s0) :\n",
    "    # Implementation of the nearest neighbour heuristic\n",
    "    # Parameters :\n",
    "    # G : weighted networkX graph\n",
    "    # s0 : node in G\n",
    "    # Return value : tuple\n",
    "    # list of nodes, shortest Hamiltonian path starting at s0\n",
    "    # int, total weight of the path\n",
    "    # list of the nodes left unvisited\n",
    "    \n",
    "    shortest_path = [] # returned path\n",
    "    spath_w = 0 # total weight of the path\n",
    "    n = G.number_of_nodes() \n",
    "    \n",
    "    si = s0 # active node, initialised as s0\n",
    "    shortest_path.append(si) # si is added to the path\n",
    "    \n",
    "    while len(shortest_path) < n : # while there are still unvisited nodes in G\n",
    "        # the neighbors of si that has not been visited yet are stored in succ\n",
    "        succ = [] \n",
    "        for sj in G[si] :\n",
    "            if sj not in shortest_path :\n",
    "                succ.append(sj)\n",
    "        \n",
    "        succ_weight = [(s, G[si][s]['weight']) for s in succ] # weight of the edge linking si to its neighbors\n",
    "        \n",
    "        if len(succ) == 0 : # If there are no successor\n",
    "            return (shortest_path, spath_w, G.nodes()-shortest_path)\n",
    "        \n",
    "        # fiding the edge with the minimal weight\n",
    "        min_w = succ_weight[0][1] # minimal weight initialisation\n",
    "        min_s = succ_weight[0][0] # corresponding successor node\n",
    "        \n",
    "        for tupNW in succ_weight :\n",
    "            if tupNW[1] < min_w : # if a lower weight is found\n",
    "                min_w = tupNW[1] # min_w actualisation\n",
    "                min_s = tupNW[0] # min_s actualisation\n",
    "       \n",
    "        shortest_path.append(min_s) # the closest successor is added to the path\n",
    "        spath_w = spath_w + min_w\n",
    "        si = min_s # the closest successor is now the active node\n",
    "    \n",
    "    return (shortest_path, spath_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbour(Gtest, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nearest_neighbour(Gc, 'f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time complexity of each loop :\n",
    "\n",
    "- `while len(shortest_path) < n :` $n$\n",
    "    - `for sj in G[si] :` $n$\n",
    "    - `for tupNW in succ_weight :` $n$\n",
    "    \n",
    "So the time complexity of `nearest_neighbour` is $O(n \\times (n+n)) = O(2n^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gex = nx.Graph()\n",
    "Eex = [(0, 1, {'weight': 4}), (0, 4, {'weight': 4}), (0, 5, {'weight': 2}), (1, 2, {'weight': 8}), (1, 6, {'weight': 1}), (2, 3, {'weight': 5}), (2, 7, {'weight': 4}), (3, 4, {'weight': 8}), (3, 8, {'weight': 8}), (4, 9, {'weight': 10}), (5, 7, {'weight': 6}), (5, 8, {'weight': 8}), (6, 8, {'weight': 5}), (6, 9, {'weight': 2}), (7, 9, {'weight': 7})]\n",
    "Gex.add_edges_from(Eex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nearest_neighbour(Gex, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Traveling_Salesman(Gex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbour(Gex, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it fails to find the shortest Hamiltonian path in some cases, for example, in `Gex`, with `9` as a starting node, this method does not create an Hamiltonian path. And for `8` as a starting node, it creates an Hamiltonian path but not the shortest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - The Minimum Spanning Tree heuristic (MST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 - Time complexity of Prim's algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an **adjacency list** is used to represent the graph, using a  **Breadth First Search (BFS)**, all the vertices can be browsed in  $O(V + E)$ time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use a **min heap** as a priority queue to store vertices not yet included in the MST and to get the minimum weight edge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Heap is a special Tree-based data structure in which the tree is a complete binary tree. In a Min-Heap the key present at the root node must be minimum among the keys present at all of it’s children. The same property must be recursively true for all sub-trees in that Binary Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **min heap** opération has a complexity time of $O(\\log(V))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we have a total time compelxity of :\n",
    "\\begin{align*}\n",
    "    & = O(V + E) \\times O(\\log(V)) \\\\\n",
    "    & = O((V + E)\\log(V)) \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 - Prove that during each iteration of the while loop, the subgraph (W, F ) is a tree.\n",
    "\n",
    "##### Initialisation :\n",
    "For the first iteration, $W = W_0 = \\{x_0\\}$ and $F = F_0 = \\emptyset$. \n",
    "\n",
    "> Let $(x, y) \\in E$ the shortest edge such that $x \\in W$ and $y \\notin W$\n",
    "\n",
    "- $x_0$ is the only element that is in $W_0$ so $x = x_0$ ;\n",
    "\n",
    "- let $x_1$ the closest neighbor of $x_0$, $y = x_1$.\n",
    "\n",
    "> $W \\gets W \\cup y$\n",
    "\n",
    "> $F \\gets F \\cup (x, y)$\n",
    "\n",
    "We now have $W = W_1 = \\{x_0, x_1\\}$ and $F = F_1 = \\{(x_0, x_1)\\}$.\n",
    "\n",
    "$(W, F) = (W_1, F_1)$ consist of only two nodes linked by one edge so it's an acyclic and connected graph, we can say that we have a tree at the end of this first iteration.\n",
    "\n",
    "##### Heredity :\n",
    "Let's suppose that at the end of the $n^{th}$ iteration we have a tree $(W, F) = (W_n, F_n)$ with $W_n = \\{ x_0, x_1, ..., x_n\\}$.\n",
    "\n",
    "> Let $(x, y) \\in E$ the shortest edge such that $x \\in W$ and $y \\notin W$\n",
    "\n",
    "- let $(x_i, x_{n+1}) \\in E$ the shortest edge such that $x_i \\in W_n$ and $x_{n+1} \\notin W_n$ ;\n",
    "- we thus have $x = x_i$ and $y = x_{n+1}$.\n",
    "\n",
    "> $W \\gets W \\cup y$\n",
    "\n",
    "> $F \\gets F \\cup (x, y)$\n",
    "\n",
    "At the end of this $(n+1)^{th}$ iteration we have $(W, F) = (W_{n+1}, F_{n+1})$ with $W_{n+1} = \\{ x_0, x_1, ..., x_n, x_{n+1}\\}$ and $F_{n+1} = F_n \\cup \\{(x_i, x_{n+1})\\}$.\n",
    "\n",
    "As $(W_n, F_n)$ is a tree and that we created $(W_{n+1}, F_{n+1})$ by adding one node $x_{n+1}$ and connecting it to the tree $(W_n, F_n)$ with one edge $(x_i, x_{n+1})$, $(W_{n+1}, F_{n+1})$ is connected and is acyclic because we didn't add any edge between two nodes of $(W_n, F_n)$.\n",
    "(\n",
    "##### Conclusion :\n",
    "We have shown that :\n",
    "- at the end of the first iteration of the `while` loop $(W, F)$ ;\n",
    "- if we have a subgraph $(W, F) = (W_n, F_n)$ that is a tree as a precondition to any iteration, we end up with the subgraph $(W, F) = (W_{n+1}, F_{n+1})$ that is also a tree at the end of the iteration.\n",
    "\n",
    "We can thus say that, according the recurrence principle, the subgraph $(W, F)$ that we have when the exiting condition of the `while` loop $W \\neq V$ is met is a tree and that $(W, F) = (V, F)$. So the subgraph $(V, F)$ returned at the end of Prim's algorithm is a tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 - Show that the result of Prim’s algorithm is a MST\n",
    "\n",
    "We know that, if $(V, F)$ if a tree, then $|F| = |V|-1$, therefore, there is a fixed number of edges in $F$. The only way to minimize the sum of the weights of the edges of a spanning tree is to minimize each weight as we can't minimize the number of edges. At each iteration of the while loop, Prim's algorithm selects the shortest edge possible to attatch a new node to the tree so we can say that it returns a minimum spanning tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 - Write a Python function that implements Prim’s algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prims_algo(G,start):\n",
    "    # Function that recives a graph G and a starting node start, and returns a Minimum Spannin Tree MST\n",
    "    # G : weighted NetworkX graph\n",
    "    # start : node of G\n",
    "    # returned value : \n",
    "    \n",
    "    N = len(G) - 1 \n",
    "    current = start # current node\n",
    "    visited = set() # We store all the visited nodes\n",
    "    pq = pqdict.PQDict() #from the module pqdict (priority queue dictionnary) :\n",
    "    MST = []\n",
    "\n",
    "    while len(MST) < N:\n",
    "        # filling pq with the edges linking current node to its neighbors not already visited\n",
    "        for node in G.neighbors(current):\n",
    "            if node not in visited and current not in visited:\n",
    "                if (current,node) not in pq and (node,current) not in pq:\n",
    "                    w = G[current][node]['weight']\n",
    "                    pq.additem((current,node), w)\n",
    "\n",
    "        visited.add(current)\n",
    "        edge_, weight_ = pq.popitem() # We get the last tuple of the priority queue with its weight (lower weight edge)\n",
    "        \n",
    "        # removing potential edges that goes to a visited node\n",
    "        while(edge_[1] in visited):\n",
    "            edge_, weight_ = pq.popitem()\n",
    "            \n",
    "        MST.append(edge_)\n",
    "        current = edge_[1]\n",
    "\n",
    "\n",
    "    return MST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSTtest = prims_algo(Gc, 'a')\n",
    "MSTtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_edges = [n for n in Gc.edges() if n not in MSTtest]\n",
    "other_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(Gc)\n",
    "\n",
    "# nodes\n",
    "nx.draw_networkx_nodes(Gc, pos, node_size=500)\n",
    "\n",
    "# edges\n",
    "nx.draw_networkx_edges(Gc, pos, edgelist=other_edges, width=4, alpha=0.5, edge_color='b', style='dashed')\n",
    "nx.draw_networkx_edges(Gc, pos, edgelist=MSTtest, width=4)\n",
    "\n",
    "# labels\n",
    "nx.draw_networkx_labels(Gc,pos,font_size=20,font_family='sans-serif')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The triangular inequality is the following inequality:\n",
    "\\begin{equation*}\n",
    "    \\forall x, y, z \\in V, w(x, z) \\leq w(x, y) + w(y, z),\n",
    "\\end{equation*}\n",
    "\n",
    "where $w(x, y)$ is the weight of edge $x → y$ (more direct paths are shorter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5 - Assuming that the graph verifies the triangle inequality, show that the length of the Hamiltonian cycle obtained by visiting the MST is less than twice the length of the shortest Hamiltonian cycle of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the shortest Hamiltonian cycle called $H_s$ and remove an arbitrary edge. The résult is a spannig tree called $T$. So we can first write the following equality if we consider that all edge have a non-negative weight :\n",
    "\n",
    "\n",
    "> $length(T) \\leq length (H_s)$\n",
    "\n",
    "\n",
    "Now, let $P$ be the full path of the Minimum Spanning Tree (MST) denoted by $T_{MST}$. This full path will include repeated vertices. \n",
    "\n",
    "Example : {0, 1, 2, 1, 7, 1, 0, 3, 4, 5, 6, 4, 3, 0}\n",
    "\n",
    "So as you can imagine the full path $P$ traverses every edges of the $T_{MST}$ twice. So we have :\n",
    "\n",
    "\n",
    "> $length(P) = 2 \\times length (T_{min})$\n",
    "\n",
    "> $length(P) = 2 \\times length (T_{min}) \\leq length(T)$\n",
    "\n",
    "> $length(P) = 2 \\times length (T_{min}) \\leq length(T) \\leq length(H_s)$\n",
    "\n",
    "The problem is $P$ is not a proper cycle since come vertices may be visited more than once. So by using the **triangle inequality**, we delete a visit to every vertices from $P$ to obtain a proper Hamiltonian cycle denoted $H$ where the **weight does not increase**.\n",
    "\n",
    "In our example : {0, 1, 2, 7, 3, 4, 5, 6, 0}\n",
    "\n",
    "Then we get :\n",
    "\n",
    "\n",
    "> $length(H) \\leq length (P)$\n",
    "\n",
    "> $length(H) \\leq length (P) \\leq 2 \\times length (T_{min})$\n",
    "\n",
    "> $length(H) \\leq length (P) \\leq 2 \\times length (T_{min}) \\leq length(T) \\leq length(H_s)$\n",
    "\n",
    "\n",
    "So finaly we have :\n",
    "\n",
    "\n",
    "> $length(H) \\leq 2 \\times length (H_s)$\n",
    "\n",
    "\n",
    "\n",
    "QED."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
