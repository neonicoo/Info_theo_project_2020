{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical Computer Sciences Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sergio Peignier and Théotime Grohens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pqdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Graph Therory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will apply graph algorithms to study the gene regulatory network (GRN)\n",
    "of *Saccharomyces cerevisiae*. This species of yeast, it is a small single-cell eukaryote, with a short generation time, and two possible forms: an haploid one and a diploid one. Moreover, this organism can be easily cultured, and it has an important economic impact since it is extensively used for instance,\n",
    "in winemaking, baking, and brewing. Due to these characteristics, Saccharomyces cerevisiae\n",
    "is studied as an important model organism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this work we will study the **gene regulatory network** of *Saccharomyces cerevisiae*, using graph theory algorithms. The files that are provided for this project have been used in [MCK+12] , as gold-standards to assess gene regulatory network inference algorithms, and they are the result of biological experiments based on ChIP binding data [MWG + 06], and systematic transcription factor deletions [HKI07]. Hereafter we describe each dataset in details:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GRN_edges_S_cerevisiae.txt : contains the edges of the *S. cervisiae* regulatory network (from transcription factors to target genes). The intended meaning is that if there is an edge between transcription factor X and the target gene A, then X regulates the transcription of A ;\n",
    "\n",
    "- net4_transcription_factors.tsv : Is a file containing in a single column the identifiers of the transcription factors of *S. cervisiae* that were studied ;\n",
    "\n",
    "- net4_gene_ids.tsv : The two previous files, use specific identifiers to denote genes, and this file contains the gene name associated to each gene identifier ;\n",
    "\n",
    "- go_slim_mapping.tab.txt : Only columns 0 and 5 will be used in this work. Column 0 contains the gene name, and column 5 contains its Gene Ontology (GO) annotation (http://www.geneontology.org/). Notice that two different rows may give for the same gene different Gene Ontology annotations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 :  Exploration and characterization of the gene regulatory network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Load the dataset and create a NetworkX graph instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On importe les datasets avec pandas : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRN_edges_SC = pd.read_csv(\"./datas/GRN_edges_S_cerevisiae.txt\", sep = ',',  header=0)\n",
    "net4_transcription_factors = pd.read_csv(\"./datas/net4_transcription_factors.tsv\", sep = '\\n',  header=0) \n",
    "net4_gene_ids = pd.read_csv(\"./datas/net4_gene_ids.tsv\", sep = '\\t', header=0) \n",
    "go_slim_mappingtab = pd.read_csv(\"./datas/go_slim_mapping.tab.txt\", sep = '\\t', header=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vérifie que tout a bien été importé "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRN_edges_SC = GRN_edges_SC.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on peut transformer le df en array (au cas où si besoin)\n",
    "GRN_edges_SC_np = GRN_edges_SC.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net4_gene_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net4_transcription_factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_slim_mappingtab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRN_edges_SC.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le dataset a bien été importé, on créé donc un graphe $G = <V,E>$ dont l'ensemble des noeuds noté $V$ contient les facteurs de transcription et les gènes cibles et l'ensemble des arettes noté $E$ représente les régulations des gènes par les facteurs de transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(GRN_edges_SC, \"transcription_factor\", \"target_gene\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Plot the gene regulatory network,  the plot should be readable,  understandable,  andinformative.  Which information did you decide to convey in your plot?  Why?\n",
    "\n",
    "On représente le graphe G tel quel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Premiere impression pour le graphe \n",
    "plt.figure(figsize=(15,8))\n",
    "nx.draw(G, node_size = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On transforme G en graphe dirigé (pas super utile et prend bcp de temps à charger)\n",
    "#G = nx.DiGraph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On rend le graphe plus lisible \n",
    "plt.figure(figsize=(18,10))\n",
    "pos = nx.spring_layout(G, k = 0.6,) #return the relative positions of the nodes,k = optimal distance between nodes\n",
    "nx.draw(G, node_size = 18, \n",
    "        pos = pos, \n",
    "        width = 0.4, \n",
    "        node_color = 'cyan',\n",
    "        edge_color = 'DarkSlateGray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le graphe n'est pas lisible tel quel et ne donne aucune information sur la nature des données.\n",
    "\n",
    "L'ensemble $V$ peut être séparé en deux sous-ensembles :\n",
    "\n",
    "- $X$ : ensemble des facteurs de transcription ;\n",
    "- $A$ : ensemble des gènes.\n",
    "\n",
    "Il serait donc plus \n",
    "isdjocospjdkpl de représenter les deux sous-ensembles $X$ et $A$ de façon distincte. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graphe bipartite :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import bipartite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_nodes_from(GRN_edges_SC['transcription_factor'], bipartite = 'transcription_factor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_nodes_from(GRN_edges_SC['target_gene'], bipartite = 'target_gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_edges_from(zip(GRN_edges_SC['transcription_factor'], GRN_edges_SC['target_gene']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf = transcription_factor\n",
    "tf_nodes = [ n for n in g.nodes() if g.nodes[n]\n",
    "            ['bipartite'] == 'transcription_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gn = gene = target_gene\n",
    "gn_nodes = [ n for n in g.nodes() if g.nodes[n]\n",
    "           ['bipartite'] == 'target_gene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ = nx.bipartite_layout(g, tf_nodes, scale = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur le graphe si-dessous, on réprésente la bipartie du graphe avec :\n",
    "\n",
    "- À gauche les noeuds représentant les facteurs de transcription;\n",
    "- À droite les noeuds représentant les gène cible pour une régulation.\n",
    "\n",
    "Globalement (sur une vue d'ensemble) on remarque tout de suite que certain facteurs agissent sur un plus grand nombre de gène cibles que d'autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "nx.draw(g, pos = pos_, node_size = 14,\n",
    "       node_color = 'forestgreen',\n",
    "       edge_color = 'darkblue',\n",
    "       width = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Describe the network by computing pertinent local and global metrics,  explain your choices, represent the results graphically if necessary, and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering coeff : en fait ça sert à R je crois vu kon a un bipartire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_clust = nx.clustering(G, tf_nodes)\n",
    "gn_clust = nx.clustering(G, gn_nodes)\n",
    "clustering = [[k for k in tf_clust.values()], [k for k in gn_clust.values()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Clustering Coefficient\",fontsize=20)\n",
    "plt.ylabel(\"Nodes\",fontsize=20)\n",
    "plt.title(\"Histogram of clustering coefficients\", fontsize=20)\n",
    "\n",
    "x1 = clustering[1]\n",
    "x2 = clustering[0]\n",
    "plt.hist([x1, x2], color = ['coral', 'mediumorchid'], \n",
    "         edgecolor = 'black', label = [\"gene's nodes\", \"TGF's nodes\"])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Clustering Coefficient\",fontsize=20)\n",
    "plt.ylabel(\"Nodes\",fontsize=20)\n",
    "plt.title(\"Histogram of clustering coefficients\", fontsize=20)\n",
    "\n",
    "x1 = clustering[1]\n",
    "plt.hist(x1, color = ['coral'], \n",
    "         edgecolor = 'black', label = [\"gene's nodes\"])\n",
    "\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Clustering Coefficient\",fontsize=20)\n",
    "plt.ylabel(\"Nodes\",fontsize=20)\n",
    "plt.title(\"Histogram of clustering coefficients\", fontsize=20)\n",
    "\n",
    "x2 = clustering[0]\n",
    "plt.hist(x2, color = ['blue'], \n",
    "         edgecolor = 'black', label = [\"TGF's nodes\"])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(clustering[1], alpha=0.6)\n",
    "plt.hist(clustering[0], alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(clustering[0]))\n",
    "print(np.mean(clustering[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_clustering(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap (G):\n",
    "    out = []\n",
    "    for couple in nx.utils.pairwise(G.nodes()):\n",
    "        n = 0\n",
    "        for nei in G[couple[0]]:\n",
    "            if nei in G[couple[1]]:\n",
    "                n+=1\n",
    "        if n == 0:\n",
    "            O = 0\n",
    "        elif  G.degree(couple[0]) <= 1 or G.degree(couple[1]) <= 1:\n",
    "            O = 0\n",
    "        elif (G.degree(couple[0])-1+G.degree(couple[1])-1-n) == 0:\n",
    "            print(G.degree(couple[0]),G.degree(couple[1]),n)\n",
    "            O=100\n",
    "        else :\n",
    "            O =  n/(G.degree(couple[0])-1+G.degree(couple[1])-1-n)\n",
    "        out.append((couple, O))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.closeness_centrality(G) # inverse de la dist moyenne entre n et les autre noeuds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.betweenness_centrality(G) # fraction of shortest paths that passes through n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.density(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RC = nx.rich_club_coefficient(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = sorted(RC.items()) # sorted by key, return a list of tuples\n",
    "\n",
    "x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"Degree k\",fontsize=10)\n",
    "plt.ylabel(\"Rich Club Coefficient\",fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_degree_dist(G):\n",
    "    degrees = [G.degree(n) for n in G.nodes()]\n",
    "    plt.hist(degrees)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_freq = nx.degree_histogram(G)\n",
    "degrees = range(len(degree_freq))\n",
    "plt.figure(figsize=(12, 8)) \n",
    "plt.loglog(degrees, degree_freq) \n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Implement and apply the k-shell decomposition algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first try to make a k-shell with a function `k_shell` directly implemented in the `networkx.algorithms.core` library, for different $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.core import k_shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(nx.k_shell(G, k=2), node_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(k_shell(G, k=4), node_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(k_shell(G, k=6), node_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(k_shell(G, k=7), node_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $k > 7$ there is no more node left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet we try to implement ourself the `k_shell` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_kshell (G, k) :\n",
    "    degrees = []\n",
    "    GG = nx.Graph()\n",
    "    GG.add_nodes_from(g)\n",
    "    GG.add_edges_from(g.edges)\n",
    "    \n",
    "    ik = 1\n",
    "    for ik in range(k):\n",
    "        done = False\n",
    "        while not done :\n",
    "            rm = []\n",
    "            for n in GG.nodes():\n",
    "                if GG.degree(n)<=ik:\n",
    "                    rm.append(n)\n",
    "            for m in rm:\n",
    "                GG.remove_node(m)\n",
    "            done = True\n",
    "            for n in GG.nodes():\n",
    "                if GG.degree(n)<=ik:\n",
    "                    done = False\n",
    "                    break\n",
    "            \n",
    "    return GG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_G = my_kshell(G, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(new_G, node_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) For at least 4 of the metrics that you have used:  what is the time complexity of the algorithm that calculates it (explain)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 : Community detection\n",
    "\n",
    "#### 1) You can choose between the Girvan Newman method and the Louvain algorithm tofind communities in the graph. Describe both algorithms, and their time complexities (explain)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Girvan Newman method :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can express Girvan-Newman algorithm in the following procedure:\n",
    "- Calculate edge betweenness for every edge in the graph ;\n",
    "- Remove the edge with highest edge betweenness ;\n",
    "- Calculate edge betweenness for remaining edges ;\n",
    "- Repeat steps 2–4 until all edges are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In its simplest and fastest form - worst-case time $O(E^{2}V$) on a network with $E$ edges and $V$ vertices, or $O(E^{3})$ on a sparse graph (where $V = E$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from networkx.algorithms.community.centrality import girvan_newman\n",
    "#partition_girvan_newman = girvan_newman(G)\n",
    "#list(partition_girvan_newman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Louvain algorithm :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method consists of two phases :\n",
    "- The first step is to look for \"small\" communities by optimizing modularity in a local way, where the modularity quantifies the quality of an assignment of nodes to communities. \n",
    "- The second step consist of an aggregation of nodes from the same community and to build a new network whose nodes are the communities. \n",
    "\n",
    "These steps are repeated iteratively until a maximum of modularity is attained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The algorithm is:\n",
    "\n",
    "- Start with each node being a singleton cluster: \n",
    "- Consider nodes in random order.\n",
    "- Iterate as long as cluster membership changes \n",
    "     - for each node : remove it from its current cluster and add it to the cluster with the highest modularity gain \n",
    "- aggregate the resulting clustering to a new graph and continue on next level (step 1), as long as modularity improves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time complexity of the Louvain algorithm is $O(V \\log(V))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Which algorithm did you choose, why ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) For the the Girvan Newman method, the user should select one of the output partitions, explain the criterion that could be used to make this choice, and its complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Study the GO composition of each community.  To do this you can produce a countingmatrix $M$,  such  that $M_{i,j}$ is  the  number  of  genes  from  community $j$ that  have  GO annotation $i^1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Is there a relationship between graph communities and particular cell functions ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Around the Traveling Salesman Problem\n",
    "### 2.1 - Exact solution\n",
    "\n",
    "In a complete graph, every node is adjacent to every other node. Therefore, if we take all the nodes in a complete graph in any order, there will be a path through those nodes in that order. (Then, if we join either end of that path, it will give us a Hamilton path.) ?\n",
    "\n",
    "Let's define an Hamiltonian path $(n_0, n_1, n_2,...,n_n)$ in a complete graph of size $n$. There are $n$ possible starting nodes $n_0$. Then, as one of the $n$ nodes has already been visited, only $n-1$ options are left for $n_1$, $n-2$ for $n_2$ and so on until there is only one node left unvisited : $n_n$. Thus, there are $n\\times n-1 \\times n-2 \\times ... \\times 1 = n!$ distinct Hamiltonian paths in a complete graph of size $n$.\n",
    "\n",
    "\n",
    "In fact, not all these path possibilities are different. On any such cycle, there are:\n",
    "- $n$ differents nodes where you can start the path ;\n",
    "- The path is reversible, you can travel it through $2$ directions.\n",
    "\n",
    "So any one of these $n!$ possible paths is in a set of $2n$ cycles which all contain the same set of edges.\n",
    "So finaly get $\\frac{n!}{2n} = \\frac{(n-1)!}{2}$ distinct Hamilton paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Our complet graph (just a test for folowing algorithms)\n",
    "\n",
    "Gc = nx.Graph()\n",
    "Gc = nx.complete_graph(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
    "list(Gc.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weight(G) :\n",
    "    for e in G.edges():\n",
    "        G[e[0]][e[1]]['weight'] = random.randrange(0,10)+1\n",
    "        #print(e, Gc[e[0]][e[1]]['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def draw_weight(G):\n",
    "    wwidth = [d['weight'] for (u, v, d) in G.edges(data=True)]\n",
    "\n",
    "    pos = nx.spring_layout(G)  # positions for all nodes\n",
    "\n",
    "    # nodes\n",
    "    nx.draw_networkx_nodes(G, pos)\n",
    "\n",
    "    # edges\n",
    "    nx.draw_networkx_edges(G, pos, width=wwidth)\n",
    "\n",
    "    # labels\n",
    "    nx.draw_networkx_labels(G, pos, font_size=20, font_family=\"sans-serif\")\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_weight(Gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_weight(Gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gtest = nx.petersen_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_weight(Gtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_weight(Gtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def succ(G, si, pred) : # returns successors of si that are not in pred\n",
    " \n",
    "    si_succ_init = [s for s in G[si]]\n",
    "    si_succ = []\n",
    "    \n",
    "    for sj in si_succ_init :\n",
    "        if sj not in pred :\n",
    "            si_succ.append(sj)\n",
    "            \n",
    "    return si_succ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_step(G, si, pred, path, weight, path_weight) :\n",
    "    if len(pred)>0 :\n",
    "        sp = pred[len(pred)-1]\n",
    "        si_w = G[sp][si]['weight']\n",
    "        weight = weight + si_w\n",
    "    pred = pred + [si] # si is added to the predecessor list\n",
    "    si_succ = succ(G, si, pred) # successors of si that are not in pred\n",
    "    \n",
    "    for sj in si_succ :\n",
    "        next_step(G, sj, pred, path, weight, path_weight)\n",
    "    \n",
    "    # when each branch has been visited as deep as possible, the list of predecessor is added to path\n",
    "    if len(si_succ) == 0 :\n",
    "        path.append(pred)\n",
    "        path_weight.append((pred, weight))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_path(G, s0) :\n",
    "    pred = []   \n",
    "    path = []\n",
    "    path_weight = []\n",
    "    weight = 0\n",
    "    \n",
    "    next_step(G, s0, pred, path, weight, path_weight)\n",
    "        \n",
    "    return path_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ham_path_filt(G, path_w) :\n",
    "    # filters out all paths that passes through less nodes than n, with n the number of nodes in G\n",
    "    # G : networkX graph\n",
    "    # path_w : list of tuples containing the paths to filter and there weight\n",
    "    \n",
    "    n = len(G.nodes())\n",
    "    ham_path = []\n",
    "    \n",
    "    for tup in path_w :\n",
    "        if len(tup[0]) >= n :\n",
    "            ham_path.append(tup)\n",
    "            \n",
    "    return ham_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hamiltonian_path(G, s0) :\n",
    "          \n",
    "    return ham_path_filt(G, find_path(G, s0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Hamiltonian_path(Gtest, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gc_path = Hamiltonian_path(Gc, 'a')\n",
    "Gc_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_Gc_path = len(Gc_path)\n",
    "n = len(Gc.nodes())\n",
    "print(N_Gc_path == math.factorial(n-1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we showed before, we can find $n!$ Hamiltonian paths in a complete graph of size $n$. Here we know the starting node $n_1$ so we don't have the $n$ options for $n_1$ but only one, so we end up with $\\frac{n!}{n} = (n-1)!$ Hamiltonian paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path(path_w) :\n",
    "    w_min = path_w[0][1]\n",
    "    path_min = []\n",
    "    \n",
    "    for tup in path_w :\n",
    "        if tup[1] < w_min :\n",
    "            w_min = tup[1]\n",
    "            path_min = [tup]\n",
    "        elif tup[1] == w_min :\n",
    "            path_min.append(tup)\n",
    "            \n",
    "    return path_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_ham_path(G, s0) :\n",
    "    path_w = Hamiltonian_path(G, s0)\n",
    "    path_min = shortest_path(path_w)\n",
    "            \n",
    "    return path_min\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gc_min_path = shortest_ham_path(Gc, 'a')\n",
    "Gtest_min_path = shortest_ham_path(Gtest, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gc_min_path', Gc_min_path)\n",
    "print('Gtest_min_path', Gtest_min_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the research of all Hamiltonian paths, `si_succ`, on which we loop, gets smaller as we go deeper. For `si = s0`, the maximum size of `si_succ` is $n$ (if we can have an edge that liks `si` to itself), then as we go a step deeper, the maximum size of `si_succ` is $n-1$, then $n-2$, and so on. The time complexity of the method `Hamiltonian_path` is $O(n!)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Traveling_Salesman(G) :\n",
    "    path_w = []\n",
    "    for s in G.nodes() :\n",
    "        path_w = path_w + Hamiltonian_path(G, s)\n",
    "    \n",
    "    path_min = shortest_path(path_w)\n",
    "    \n",
    "    return path_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Traveling_Salesman(Gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Traveling_Salesman(Gtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - The Nearest Neighbor heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbour(G, s0) :\n",
    "    # Implementation of the nearest neighbour heuristic\n",
    "    # Parameters :\n",
    "    # G : weighted networkX graph\n",
    "    # s0 : node in G\n",
    "    # Return value : tuple\n",
    "    # list of nodes, shortest Hamiltonian path starting at s0\n",
    "    # int, total weight of the path\n",
    "    # list of the nodes left unvisited\n",
    "    \n",
    "    shortest_path = [] # returned path\n",
    "    spath_w = 0 # total weight of the path\n",
    "    n = G.number_of_nodes() \n",
    "    \n",
    "    si = s0 # active node, initialised as s0\n",
    "    shortest_path.append(si) # si is added to the path\n",
    "    \n",
    "    while len(shortest_path) < n : # while there are still unvisited nodes in G\n",
    "        # the neighbors of si that has not been visited yet are stored in succ\n",
    "        succ = [] \n",
    "        for sj in G[si] :\n",
    "            if sj not in shortest_path :\n",
    "                succ.append(sj)\n",
    "        \n",
    "        succ_weight = [(s, G[si][s]['weight']) for s in succ] # weight of the edge linking si to its neighbors\n",
    "        \n",
    "        if len(succ) == 0 : # If there are no successor\n",
    "            return (shortest_path, spath_w, G.nodes()-shortest_path)\n",
    "        \n",
    "        # fiding the edge with the minimal weight\n",
    "        min_w = succ_weight[0][1] # minimal weight initialisation\n",
    "        min_s = succ_weight[0][0] # corresponding successor node\n",
    "        \n",
    "        for tupNW in succ_weight :\n",
    "            if tupNW[1] < min_w : # if a lower weight is found\n",
    "                min_w = tupNW[1] # min_w actualisation\n",
    "                min_s = tupNW[0] # min_s actualisation\n",
    "       \n",
    "        shortest_path.append(min_s) # the closest successor is added to the path\n",
    "        spath_w = spath_w + min_w\n",
    "        si = min_s # the closest successor is now the active node\n",
    "    \n",
    "    return (shortest_path, spath_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbour(Gtest, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nearest_neighbour(Gc, 'f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time complexity of each loop :\n",
    "\n",
    "- `while len(shortest_path) < n :` $n$\n",
    "    - `for sj in G[si] :` $n$\n",
    "    - `for tupNW in succ_weight :` $n$\n",
    "    \n",
    "So the time complexity of `nearest_neighbour` is $O(n \\times (n+n)) = O(2n^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gex = nx.Graph()\n",
    "Eex = [(0, 1, {'weight': 4}), (0, 4, {'weight': 4}), (0, 5, {'weight': 2}), (1, 2, {'weight': 8}), (1, 6, {'weight': 1}), (2, 3, {'weight': 5}), (2, 7, {'weight': 4}), (3, 4, {'weight': 8}), (3, 8, {'weight': 8}), (4, 9, {'weight': 10}), (5, 7, {'weight': 6}), (5, 8, {'weight': 8}), (6, 8, {'weight': 5}), (6, 9, {'weight': 2}), (7, 9, {'weight': 7})]\n",
    "Gex.add_edges_from(Eex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nearest_neighbour(Gex, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Traveling_Salesman(Gex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbour(Gex, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it fails to find the shortest Hamiltonian path in some cases, for example, in `Gex`, with `9` as a starting node, this method does not create an Hamiltonian path. And for `8` as a starting node, it creates an Hamiltonian path but not the shortest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - The Minimum Spanning Tree heuristic (MST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using an appropriate data structure, what is the time complexity of this algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an **adjacency list** is used to represent the graph, using a  **Breadth First Search (BFS)**, all the vertices can be browsed in  $O(V + E)$ time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use a **min heap** as a priority queue to store vertices not yet included in the MST and to get the minimum weight edge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Heap is a special Tree-based data structure in which the tree is a complete binary tree. In a Min-Heap the key present at the root node must be minimum among the keys present at all of it’s children. The same property must be recursively true for all sub-trees in that Binary Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **min heap** opération has a complexity time of $O(\\log(V))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we have a total time compelxity of :\n",
    "\\begin{align*}\n",
    "    & = O(V + E) \\times O(\\log(V)) \\\\\n",
    "    & = O((V + E)\\log(V)) \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prove that during each iteration of the while loop, the subgraph (W, F ) is a tree.\n",
    "\n",
    "##### Initialisation :\n",
    "For the first iteration, $W = W_0 = \\{x_0\\}$ and $F = F_0 = \\emptyset$. \n",
    "\n",
    "> Let $(x, y) \\in E$ the shortest edge such that $x \\in W$ and $y \\notin W$\n",
    "\n",
    "- $x_0$ is the only element that is in $W_0$ so $x = x_0$ ;\n",
    "\n",
    "- let $x_1$ the closest neighbor of $x_0$, $y = x_1$.\n",
    "\n",
    "> $W \\gets W \\cup y$\n",
    "\n",
    "> $F \\gets F \\cup (x, y)$\n",
    "\n",
    "We now have $W = W_1 = \\{x_0, x_1\\}$ and $F = F_1 = \\{(x_0, x_1)\\}$.\n",
    "\n",
    "$(W, F) = (W_1, F_1)$ consist of only two nodes linked by one edge so it's an acyclic and connected graph, we can say that we have a tree at the end of this first iteration.\n",
    "\n",
    "##### Heredity :\n",
    "Let's suppose that at the end of the $n^{th}$ iteration we have a tree $(W, F) = (W_n, F_n)$ with $W_n = \\{ x_0, x_1, ..., x_n\\}$.\n",
    "\n",
    "> Let $(x, y) \\in E$ the shortest edge such that $x \\in W$ and $y \\notin W$\n",
    "\n",
    "- let $(x_i, x_{n+1}) \\in E$ the shortest edge such that $x_i \\in W_n$ and $x_{n+1} \\notin W_n$ ;\n",
    "- we thus have $x = x_i$ and $y = x_{n+1}$.\n",
    "\n",
    "> $W \\gets W \\cup y$\n",
    "\n",
    "> $F \\gets F \\cup (x, y)$\n",
    "\n",
    "At the end of this $(n+1)^{th}$ iteration we have $(W, F) = (W_{n+1}, F_{n+1})$ with $W_{n+1} = \\{ x_0, x_1, ..., x_n, x_{n+1}\\}$ and $F_{n+1} = F_n \\cup \\{(x_i, x_{n+1})\\}$.\n",
    "\n",
    "As $(W_n, F_n)$ is a tree and that we created $(W_{n+1}, F_{n+1})$ by adding one node $x_{n+1}$ and connecting it to the tree $(W_n, F_n)$ with one edge $(x_i, x_{n+1})$, $(W_{n+1}, F_{n+1})$ is connected and is acyclic because we didn't add any edge between two nodes of $(W_n, F_n)$.\n",
    "(\n",
    "##### Conclusion :\n",
    "We have shown that :\n",
    "- at the end of the first iteration of the `while` loop $(W, F)$ ;\n",
    "- if we have a subgraph $(W, F) = (W_n, F_n)$ that is a tree as a precondition to any iteration, we end up with the subgraph $(W, F) = (W_{n+1}, F_{n+1})$ that is also a tree at the end of the iteration.\n",
    "\n",
    "We can thus say that, according the recurrence principle, the subgraph $(W, F)$ that we have when the exiting condition of the `while` loop $W \\neq V$ is met is a tree and that $(W, F) = (V, F)$. So the subgraph $(V, F)$ returned at the end of Prim's algorithm is a tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deduce that Prim’s algorithm returns a spanning tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a Python function that implements Prim’s algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function recives a graph and a starting node, and returns a MST : \n",
    "\n",
    "def prims_algo(G,start):\n",
    "    N = len(G) - 1\n",
    "    current = start\n",
    "    visited = set() # We store all the visited nodes\n",
    "    pq = pqdict.PQDict() #from the module pqdict (priority queue dictionnary) :\n",
    "    MST = []\n",
    "\n",
    "    while len(MST) < N:\n",
    "        for node in G.neighbors(current):\n",
    "            if node not in visited and current not in visited:\n",
    "                if (current,node) not in pq and (node,current) not in pq:\n",
    "                    w = G[current][node]['weight']\n",
    "                    pq.additem((current,node), w)\n",
    "\n",
    "        visited.add(current)\n",
    "        edge_, weight_ = pq.popitem() # We get the last tuple of the priority queue with its weight\n",
    "        \n",
    "        while(edge_[1] in visited):\n",
    "            edge_, weight_ = pq.popitem()\n",
    "        MST.append(edge_)\n",
    "        current = edge_[1]\n",
    "\n",
    "    return MST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSTtest = prims_algo(Gtest, 0)\n",
    "MSTtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_edges = [n for n in Gtest.edges() if n not in MSTtest]\n",
    "other_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(Gtest)\n",
    "\n",
    "# nodes\n",
    "nx.draw_networkx_nodes(Gtest, pos, node_size=500)\n",
    "\n",
    "# edges\n",
    "nx.draw_networkx_edges(Gtest, pos, edgelist=MSTtest, width=4)\n",
    "nx.draw_networkx_edges(Gtest, pos, edgelist=other_edges, width=4, alpha=0.5, edge_color='b', style='dashed')\n",
    "\n",
    "# labels\n",
    "nx.draw_networkx_labels(Gtest,pos,font_size=20,font_family='sans-serif')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The triangular inequality is the following inequality:\n",
    "\\begin{equation*}\n",
    "    \\forall x, y, z \\in V, w(x, z) \\leq w(x, y) + w(y, z),\n",
    "\\end{equation*}\n",
    "\n",
    "where $w(x, y)$ is the weight of edge $x → y$ (more direct paths are shorter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assuming that the graph verifies the triangle inequality, show that the length of the Hamiltonian cycle obtained by visiting the MST is less than twice the length of the shortest Hamiltonian cycle of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the shortest Hamiltonian cycle called $H_s$ and remove an arbitrary edge. The résult is a spannig tree called $T$. So we can first write the following equality if we consider that all edge have a non-negative weight :\n",
    "\n",
    "\n",
    "> $length(T) \\leq length (H_s)$\n",
    "\n",
    "\n",
    "Now, let $P$ be the full path of the Minimum Spanning Tree (MST) denoted by $T_{MST}$. This full path will include repeated vertices. \n",
    "\n",
    "Example : {0, 1, 2, 1, 7, 1, 0, 3, 4, 5, 6, 4, 3, 0}\n",
    "\n",
    "So as you can imagine the full path $P$ traverses every edges of the $T_{MST}$ twice. So we have :\n",
    "\n",
    "\n",
    "> $length(P) = 2 \\times length (T_{min})$\n",
    "\n",
    "> $length(P) = 2 \\times length (T_{min}) \\leq length(T)$\n",
    "\n",
    "> $length(P) = 2 \\times length (T_{min}) \\leq length(T) \\leq length(H_s)$\n",
    "\n",
    "The problem is $P$ is not a proper cycle since come vertices may be visited more than once. So by using the **triangle inequality**, we delete a visit to every vertices from $P$ to obtain a proper Hamiltonian cycle denoted $H$ where the **weight does not increase**.\n",
    "\n",
    "In our example : {0, 1, 2, 7, 3, 4, 5, 6, 0}\n",
    "\n",
    "Then we get :\n",
    "\n",
    "\n",
    "> $length(H) \\leq length (P)$\n",
    "\n",
    "> $length(H) \\leq length (P) \\leq 2 \\times length (T_{min})$\n",
    "\n",
    "> $length(H) \\leq length (P) \\leq 2 \\times length (T_{min}) \\leq length(T) \\leq length(H_s)$\n",
    "\n",
    "\n",
    "So finaly we have :\n",
    "\n",
    "\n",
    "> $length(H) \\leq 2 \\times length (H_s)$\n",
    "\n",
    "\n",
    "\n",
    "QED."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
